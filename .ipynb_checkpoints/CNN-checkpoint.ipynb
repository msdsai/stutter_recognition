{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e3db3fa-6444-4245-b925-804b87836ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import medfilt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260c2936-6b93-4997-aaa8-2107734df0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './digits'  # Folder with fluent/ and stutter/\n",
    "SAMPLE_RATE = 16000\n",
    "N_MFCC = 12\n",
    "MAX_LEN = 160  # max frame length for MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01de7f1-47c0-4d8a-abc0-904681b67248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_file(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Filter only lines that contain numbers\n",
    "    numeric_lines = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            float(line.strip())  # Try converting\n",
    "            numeric_lines.append(line.strip())\n",
    "        except ValueError:\n",
    "            continue  # Skip headers or non-numeric lines\n",
    "\n",
    "    return np.array([float(x) for x in numeric_lines])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b642ef3-7a77-4c37-8d51-88a20362a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_median_filter(signal):\n",
    "    return medfilt(signal, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37690d6f-c85c-4067-ba09-837994e47cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_filter(y):\n",
    "    return gaussian_filter1d(y, sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e32bb6-cdb4-410a-87f2-a018896a3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(y, sr):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55035e37-8af2-4728-87fa-6d234b08e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filepath):\n",
    "    y = read_txt_file(filepath)\n",
    "    y = librosa.util.fix_length(y, size=SAMPLE_RATE)  # trim or pad\n",
    "\n",
    "    y_median = apply_median_filter(y)\n",
    "    y_gaussian = apply_gaussian_filter(y)\n",
    "    # y_clean = y_median\n",
    "    y_vlean = y_gaussian\n",
    "    mfcc = extract_mfcc(y_clean, SAMPLE_RATE)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8aba1c7-a3ff-4e4d-b6af-92b450b70268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    X = []\n",
    "    y = []\n",
    "    filenames = []\n",
    "    labels = {'fluent': 0, 'prolong': 1, 'repeat': 2}\n",
    "\n",
    "    # Fluent\n",
    "    fluent_path = os.path.join(DATASET_PATH, 'fluent')\n",
    "    for file in os.listdir(fluent_path):\n",
    "        if file.endswith('.txt'):\n",
    "            mfcc = process_file(os.path.join(fluent_path, file))\n",
    "            X.append(mfcc)\n",
    "            y.append(labels['fluent'])\n",
    "            filenames.append(file)    \n",
    "\n",
    "    # Stutter - prolong\n",
    "    prolong_path = os.path.join(DATASET_PATH, 'stutter', 'prolong')\n",
    "    for file in os.listdir(prolong_path):\n",
    "        if file.endswith('.txt'):\n",
    "            mfcc = process_file(os.path.join(prolong_path, file))\n",
    "            X.append(mfcc)\n",
    "            y.append(labels['prolong'])\n",
    "            filenames.append(file)\n",
    "\n",
    "    # Stutter - repeations\n",
    "    repeations_path = os.path.join(DATASET_PATH, 'stutter', 'repeat')\n",
    "    for file in os.listdir(repeations_path):\n",
    "        if file.endswith('.txt'):\n",
    "            mfcc = process_file(os.path.join(repeations_path, file))\n",
    "            X.append(mfcc)\n",
    "            y.append(labels['repeat'])\n",
    "            filenames.append(file)\n",
    "\n",
    "    return np.array(X), np.array(y), np.array(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "620826a0-139b-4887-b8fe-fc6a72a392ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, filenames = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99987349-7579-48f6-8d70-58a496b71db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded = np.array([np.pad(x, ((0,0), (0, MAX_LEN - x.shape[1])), mode='constant')[:, :MAX_LEN] for x in X])\n",
    "X_padded = X_padded[..., np.newaxis]  # add channel dimension\n",
    "y_cat = to_categorical(y, num_classes=3)\n",
    "X_train, X_test, y_train, y_test, filenames_train, filenames_test = train_test_split(X_padded, y_cat, filenames, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ce2ad06-5a0f-47ad-83af-8c30a758eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build CNN Model ---\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=X_padded.shape[1:]),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "555ff80e-de6e-4ad1-b58a-aa7744f2573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 10, 158, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 5, 79, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 5, 79, 32)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 3, 77, 64)         18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 1, 38, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1, 38, 64)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2432)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               311424    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330627 (1.26 MB)\n",
      "Trainable params: 330627 (1.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22c930e2-7d25-4c6b-967d-396b5f4ad8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 3s 215ms/step - loss: 15.0056 - accuracy: 0.4375 - val_loss: 0.6302 - val_accuracy: 0.8250\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 4.9722 - accuracy: 0.6250 - val_loss: 1.3368 - val_accuracy: 0.7250\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 3.2733 - accuracy: 0.7375 - val_loss: 0.1034 - val_accuracy: 0.9750\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 2.1615 - accuracy: 0.7063 - val_loss: 0.1860 - val_accuracy: 0.9000\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 1.2732 - accuracy: 0.7188 - val_loss: 0.1869 - val_accuracy: 0.9250\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 1.3747 - accuracy: 0.7688 - val_loss: 0.1726 - val_accuracy: 0.9250\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.9710 - accuracy: 0.7875 - val_loss: 0.1044 - val_accuracy: 0.9500\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.5624 - accuracy: 0.8250 - val_loss: 0.1214 - val_accuracy: 0.9500\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.5666 - accuracy: 0.7875 - val_loss: 0.2467 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.5471 - accuracy: 0.8625 - val_loss: 0.3036 - val_accuracy: 0.8750\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.3666 - accuracy: 0.8625 - val_loss: 0.1523 - val_accuracy: 0.9500\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.2972 - accuracy: 0.8750 - val_loss: 0.1455 - val_accuracy: 0.9250\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.2823 - accuracy: 0.9000 - val_loss: 0.1592 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2571 - accuracy: 0.9125 - val_loss: 0.1055 - val_accuracy: 0.9500\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 0.2725 - accuracy: 0.9187 - val_loss: 0.0908 - val_accuracy: 0.9750\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.3159 - accuracy: 0.9125 - val_loss: 0.1330 - val_accuracy: 0.9750\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.2147 - accuracy: 0.8875 - val_loss: 0.1660 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.1766 - accuracy: 0.9250 - val_loss: 0.1520 - val_accuracy: 0.9750\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.3029 - accuracy: 0.8938 - val_loss: 0.1548 - val_accuracy: 0.9500\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1767 - accuracy: 0.9250 - val_loss: 0.1445 - val_accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "# --- Train ---\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c56ce6f6-d5bd-42d1-a599-ebe5e5ecb7eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step\n",
      "Filename                       Actual       Predicted   \n",
      "============================================================\n",
      "210101063_E_9_5.txt            fluent       fluent      \n",
      "210101063_E_1_5.txt            fluent       fluent      \n",
      "210101063_E_3_1.txt            fluent       fluent      \n",
      "210101063_repeat_1_4.txt       repeations   repeations  \n",
      "210101063_prolong_5_4.txt      prolong      prolong     \n",
      "210101063_prolong_3_1.txt      prolong      prolong     \n",
      "210101063_E_6_9.txt            fluent       fluent      \n",
      "210101063_repeat_4_1.txt       repeations   repeations  \n",
      "210101063_repeat_4_5.txt       repeations   repeations  \n",
      "210101063_E_4_5.txt            fluent       fluent      \n",
      "210101063_E_6_6.txt            fluent       fluent      \n",
      "210101063_repeat_6_3.txt       repeations   repeations  \n",
      "210101063_repeat_3_1.txt       repeations   repeations  \n",
      "210101063_E_7_8.txt            fluent       fluent      \n",
      "210101063_repeat_7_2.txt       repeations   repeations  \n",
      "210101063_repeat_5_3.txt       repeations   repeations  \n",
      "210101063_E_5_6.txt            fluent       fluent      \n",
      "210101063_repeat_0_3.txt       repeations   repeations  \n",
      "210101063_E_8_2.txt            fluent       fluent      \n",
      "210101063_E_6_8.txt            fluent       fluent      \n",
      "210101063_prolong_4_5.txt      prolong      prolong     \n",
      "210101063_E_1_6.txt            fluent       fluent      \n",
      "210101063_prolong_9_4.txt      prolong      prolong     \n",
      "210101063_E_9_3.txt            fluent       fluent      \n",
      "210101063_E_6_5.txt            fluent       fluent      \n",
      "210101063_E_6_1.txt            fluent       repeations  \n",
      "210101063_E_8_4.txt            fluent       fluent      \n",
      "210101063_E_6_7.txt            fluent       fluent      \n",
      "210101063_prolong_5_1.txt      prolong      prolong     \n",
      "210101063_prolong_6_3.txt      prolong      prolong     \n",
      "210101063_E_0_9.txt            fluent       fluent      \n",
      "210101063_E_1_8.txt            fluent       fluent      \n",
      "210101063_E_5_5.txt            fluent       fluent      \n",
      "210101063_E_7_5.txt            fluent       fluent      \n",
      "210101063_repeat_0_1.txt       repeations   repeations  \n",
      "210101063_prolong_0_5.txt      prolong      prolong     \n",
      "210101063_prolong_7_1.txt      prolong      prolong     \n",
      "210101063_prolong_7_3.txt      prolong      prolong     \n",
      "210101063_repeat_2_5.txt       repeations   repeations  \n",
      "210101063_E_7_6.txt            fluent       fluent      \n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Label mapping\n",
    "label_map = {0: 'fluent', 1: 'prolong', 2: 'repeations'}\n",
    "\n",
    "# Print comparison\n",
    "print(f\"{'Filename':<30} {'Actual':<12} {'Predicted':<12}\")\n",
    "print(\"=\"*60)\n",
    "for i in range(len(filenames_test)):\n",
    "    actual = label_map[y_true_labels[i]]\n",
    "    predicted = label_map[y_pred_labels[i]]\n",
    "    print(f\"{filenames_test[i]:<30} {actual:<12} {predicted:<12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e0986f1-45f9-4ac4-a8ac-7b00e85dd7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      fluent       1.00      0.95      0.98        21\n",
      "     prolong       1.00      1.00      1.00         9\n",
      "  repeations       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.97      0.98      0.98        40\n",
      "weighted avg       0.98      0.97      0.98        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = ['fluent', 'prolong', 'repeations']\n",
    "print(\"\\nCNN Classification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62446732-9adc-408d-87c1-327791fd3a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
